{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "O trabalho embaixo é baseado no paper [Autoencoder-based Network Anomaly Detection.](https://ieeexplore.ieee.org/document/8363930)\n",
    "\n",
    "Autoencoders são um tipo de rede neural usados para codificar eficientemente um conjunto de dados, de forma não-supervisionada. Geralmente tal codificação reduz a dimensionalidade do dataset.\n",
    "\n",
    "- Há duas funções associadas: encoding e decoding.\n",
    "    - Decoding busca reverter a operação, retornando os dados ao espaço original.\n",
    "- O autoencoder mantém relações não-lineares entre dados, o que não ocorre com métodos de redução de dimensionalidade como PCA\n",
    "\n",
    "Pode-se detectar anomalias usando PCA ou Autoencoders. O processo envolve projetar os dados em um espaço de menor dimensão e, em seguida, reconstruí-los. Espera-se que os dados normais sigam o padrão aprendido durante o treinamento, resultando em um erro de reconstrução menor. As anomalias, por sua vez, apresentam um erro de reconstrução maior que um limiar ε.\n",
    "- O autoencoder convolucional usa camadas convolucionais para reduzir o tempo de processamento\n",
    "\n",
    "Framework do sistema de anomalias via autoencoder:\n",
    "\n",
    "1. Normalização dos dados\n",
    "2. Geração de dados 2D (apenas para convolucional) - usou Triangle Area Maps\n",
    "3. Treinamento do autoencoder - minimizar o erro de reconstrução médio\n",
    "4. Teste de autoencoder - usa o erro de reconstrução como a “pontuação de anomalia”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Datasets\n",
    "Usaremos dois datasets com o encoder: o que indiscrimina ataques diferentes (singleclass_df) e o que os separa em classes (multiclass_df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimenstion equals 1024\n"
     ]
    }
   ],
   "source": [
    "# Read datasets\n",
    "singleclass_df = pd.read_csv(\"files/5G_attack_detection_ds.csv\")\n",
    "multiclass_df = pd.read_csv(\"files_multiclass/mixed_mult_class.csv\")\n",
    "\n",
    "# Removes labels, normalizes and splits into testing/training sets\n",
    "def prepare_ds(df: pd.DataFrame):\n",
    "    df = df.dropna()\n",
    "\n",
    "    labels = df.iloc[:, -1]\n",
    "    features = df.iloc[:, :-1]\n",
    "\n",
    "    # Separate non-anomalous data (label = 1) for training\n",
    "    non_anomalous_data = df[df.iloc[:, -1] == 1]\n",
    "    non_anomalous_labels = non_anomalous_data.iloc[:, -1]\n",
    "    non_anomalous_features = non_anomalous_data.iloc[:, :-1]\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    non_anomalous_features_scaled = scaler.fit_transform(non_anomalous_features)\n",
    "    features_scaled = scaler.transform(features)  # Scale the entire dataset for consistency\n",
    "\n",
    "    # Use all non-anomalous data for training\n",
    "    X_train = non_anomalous_features_scaled\n",
    "    y_train = non_anomalous_labels\n",
    "\n",
    "    # Use the entire dataset (both normal and anomalous) for testing\n",
    "    X_test, y_test = features_scaled, labels\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "S_X_train, S_X_test, S_y_train, S_y_test = prepare_ds(singleclass_df)\n",
    "M_X_train, M_X_test, M_y_train, M_y_test = prepare_ds(multiclass_df)\n",
    "\n",
    "# Both datasets have the same amount of columns\n",
    "input_dimension = S_X_train.shape[1]\n",
    "\n",
    "print(f'Input dimenstion equals {input_dimension}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura do Encoder\n",
    "\n",
    "Utilizaremos a função sigmóide, como no paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m65,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m66,560\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,704</span> (537.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m137,704\u001b[0m (537.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,704</span> (537.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m137,704\u001b[0m (537.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_layer = Input(shape=(input_dimension,))\n",
    "\n",
    "# Encoder\n",
    "encoding_layer_1 = Dense(64, activation='sigmoid')(input_layer)\n",
    "encoding_layer_2 = Dense(32, activation='sigmoid')(encoding_layer_1)\n",
    "encoding_layer_3 = Dense(16, activation='sigmoid')(encoding_layer_2)\n",
    "encoding_layer_4 = Dense(8, activation='sigmoid')(encoding_layer_3)\n",
    "\n",
    "# Decoder\n",
    "decoding_layer_1 = Dense(16, activation='sigmoid')(encoding_layer_4)\n",
    "decoding_layer_2 = Dense(32, activation='sigmoid')(decoding_layer_1)\n",
    "decoding_layer_3 = Dense(64, activation='sigmoid')(decoding_layer_2)\n",
    "output_layer = Dense(input_dimension, activation='sigmoid')(decoding_layer_3)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0926 - val_loss: 0.9988\n",
      "Epoch 2/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0069 - val_loss: 0.9945\n",
      "Epoch 3/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9915 - val_loss: 0.9773\n",
      "Epoch 4/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9651 - val_loss: 0.9059\n",
      "Epoch 5/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9033 - val_loss: 0.8878\n",
      "Epoch 6/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8899 - val_loss: 0.8822\n",
      "Epoch 7/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8853 - val_loss: 0.8807\n",
      "Epoch 8/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8881 - val_loss: 0.8802\n",
      "Epoch 9/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8809 - val_loss: 0.8799\n",
      "Epoch 10/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8842 - val_loss: 0.8798\n",
      "Epoch 11/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8806 - val_loss: 0.8798\n",
      "Epoch 12/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8830 - val_loss: 0.8797\n",
      "Epoch 13/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8802 - val_loss: 0.8796\n",
      "Epoch 14/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8871 - val_loss: 0.8796\n",
      "Epoch 15/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8801 - val_loss: 0.8796\n",
      "Epoch 16/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8783 - val_loss: 0.8795\n",
      "Epoch 17/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8868 - val_loss: 0.8795\n",
      "Epoch 18/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8789 - val_loss: 0.8795\n",
      "Epoch 19/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8798 - val_loss: 0.8795\n",
      "Epoch 20/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8786 - val_loss: 0.8796\n",
      "Epoch 21/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8778 - val_loss: 0.8795\n",
      "Epoch 22/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8798 - val_loss: 0.8795\n",
      "Epoch 23/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8871 - val_loss: 0.8795\n",
      "Epoch 24/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8831 - val_loss: 0.8795\n",
      "Epoch 25/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8814 - val_loss: 0.8795\n",
      "Epoch 26/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8852 - val_loss: 0.8795\n",
      "Epoch 27/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8814 - val_loss: 0.8794\n",
      "Epoch 28/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8817 - val_loss: 0.8795\n",
      "Epoch 29/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8827 - val_loss: 0.8795\n",
      "Epoch 30/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8897 - val_loss: 0.8794\n",
      "Epoch 31/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8818 - val_loss: 0.8792\n",
      "Epoch 32/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8829 - val_loss: 0.8792\n",
      "Epoch 33/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8804 - val_loss: 0.8781\n",
      "Epoch 34/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8754 - val_loss: 0.8775\n",
      "Epoch 35/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8828 - val_loss: 0.8770\n",
      "Epoch 36/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8726 - val_loss: 0.8763\n",
      "Epoch 37/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8791 - val_loss: 0.8756\n",
      "Epoch 38/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8714 - val_loss: 0.8751\n",
      "Epoch 39/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8727 - val_loss: 0.8745\n",
      "Epoch 40/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8786 - val_loss: 0.8734\n",
      "Epoch 41/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8711 - val_loss: 0.8725\n",
      "Epoch 42/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8735 - val_loss: 0.8720\n",
      "Epoch 43/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8736 - val_loss: 0.8717\n",
      "Epoch 44/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8794 - val_loss: 0.8714\n",
      "Epoch 45/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8696 - val_loss: 0.8712\n",
      "Epoch 46/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8761 - val_loss: 0.8710\n",
      "Epoch 47/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8712 - val_loss: 0.8705\n",
      "Epoch 48/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8721 - val_loss: 0.8699\n",
      "Epoch 49/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8707 - val_loss: 0.8690\n",
      "Epoch 50/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8720 - val_loss: 0.8687\n",
      "Epoch 51/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8721 - val_loss: 0.8684\n",
      "Epoch 52/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8698 - val_loss: 0.8682\n",
      "Epoch 53/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8724 - val_loss: 0.8681\n",
      "Epoch 54/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8669 - val_loss: 0.8679\n",
      "Epoch 55/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8621 - val_loss: 0.8678\n",
      "Epoch 56/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8710 - val_loss: 0.8677\n",
      "Epoch 57/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8697 - val_loss: 0.8677\n",
      "Epoch 58/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8714 - val_loss: 0.8676\n",
      "Epoch 59/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8709 - val_loss: 0.8675\n",
      "Epoch 60/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8665 - val_loss: 0.8674\n",
      "Epoch 61/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8708 - val_loss: 0.8674\n",
      "Epoch 62/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8667 - val_loss: 0.8673\n",
      "Epoch 63/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8730 - val_loss: 0.8673\n",
      "Epoch 64/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8660 - val_loss: 0.8672\n",
      "Epoch 65/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8667 - val_loss: 0.8672\n",
      "Epoch 66/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8678 - val_loss: 0.8672\n",
      "Epoch 67/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8713 - val_loss: 0.8671\n",
      "Epoch 68/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8689 - val_loss: 0.8671\n",
      "Epoch 69/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8694 - val_loss: 0.8670\n",
      "Epoch 70/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8668 - val_loss: 0.8670\n",
      "Epoch 71/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8676 - val_loss: 0.8670\n",
      "Epoch 72/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8672 - val_loss: 0.8669\n",
      "Epoch 73/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8719 - val_loss: 0.8669\n",
      "Epoch 74/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8678 - val_loss: 0.8668\n",
      "Epoch 75/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8703 - val_loss: 0.8668\n",
      "Epoch 76/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8625 - val_loss: 0.8668\n",
      "Epoch 77/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8679 - val_loss: 0.8667\n",
      "Epoch 78/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8648 - val_loss: 0.8667\n",
      "Epoch 79/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8722 - val_loss: 0.8667\n",
      "Epoch 80/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8717 - val_loss: 0.8666\n",
      "Epoch 81/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8714 - val_loss: 0.8666\n",
      "Epoch 82/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8635 - val_loss: 0.8666\n",
      "Epoch 83/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8717 - val_loss: 0.8666\n",
      "Epoch 84/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8682 - val_loss: 0.8665\n",
      "Epoch 85/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8673 - val_loss: 0.8666\n",
      "Epoch 86/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8645 - val_loss: 0.8665\n",
      "Epoch 87/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8690 - val_loss: 0.8665\n",
      "Epoch 88/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8667 - val_loss: 0.8665\n",
      "Epoch 89/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8685 - val_loss: 0.8665\n",
      "Epoch 90/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8623 - val_loss: 0.8665\n",
      "Epoch 91/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8632 - val_loss: 0.8664\n",
      "Epoch 92/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8699 - val_loss: 0.8664\n",
      "Epoch 93/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8698 - val_loss: 0.8664\n",
      "Epoch 94/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8645 - val_loss: 0.8664\n",
      "Epoch 95/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8652 - val_loss: 0.8664\n",
      "Epoch 96/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8692 - val_loss: 0.8664\n",
      "Epoch 97/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8675 - val_loss: 0.8664\n",
      "Epoch 98/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8667 - val_loss: 0.8664\n",
      "Epoch 99/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8673 - val_loss: 0.8664\n",
      "Epoch 100/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8693 - val_loss: 0.8663\n",
      "Epoch 101/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8684 - val_loss: 0.8663\n",
      "Epoch 102/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8595 - val_loss: 0.8663\n",
      "Epoch 103/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8724 - val_loss: 0.8663\n",
      "Epoch 104/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8650 - val_loss: 0.8663\n",
      "Epoch 105/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8688 - val_loss: 0.8663\n",
      "Epoch 106/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8691 - val_loss: 0.8663\n",
      "Epoch 107/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8711 - val_loss: 0.8663\n",
      "Epoch 108/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8686 - val_loss: 0.8663\n",
      "Epoch 109/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8627 - val_loss: 0.8663\n",
      "Epoch 110/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8744 - val_loss: 0.8663\n",
      "Epoch 111/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8678 - val_loss: 0.8663\n",
      "Epoch 112/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8690 - val_loss: 0.8663\n",
      "Epoch 113/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8649 - val_loss: 0.8663\n",
      "Epoch 114/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8712 - val_loss: 0.8663\n",
      "Epoch 115/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8658 - val_loss: 0.8663\n",
      "Epoch 116/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8678 - val_loss: 0.8663\n",
      "Epoch 117/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8674 - val_loss: 0.8663\n",
      "Epoch 118/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8662 - val_loss: 0.8663\n",
      "Epoch 119/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8682 - val_loss: 0.8662\n",
      "Epoch 120/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8725 - val_loss: 0.8662\n",
      "Epoch 121/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8677 - val_loss: 0.8663\n",
      "Epoch 122/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8646 - val_loss: 0.8662\n",
      "Epoch 123/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8696 - val_loss: 0.8663\n",
      "Epoch 124/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8649 - val_loss: 0.8663\n",
      "Epoch 125/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8651 - val_loss: 0.8662\n",
      "Epoch 126/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8612 - val_loss: 0.8662\n",
      "Epoch 127/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8672 - val_loss: 0.8662\n",
      "Epoch 128/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8676 - val_loss: 0.8662\n",
      "Epoch 129/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8637 - val_loss: 0.8662\n",
      "Epoch 130/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8694 - val_loss: 0.8663\n",
      "Epoch 131/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8633 - val_loss: 0.8662\n",
      "Epoch 132/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8685 - val_loss: 0.8662\n",
      "Epoch 133/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8626 - val_loss: 0.8662\n",
      "Epoch 134/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8628 - val_loss: 0.8662\n",
      "Epoch 135/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8690 - val_loss: 0.8662\n",
      "Epoch 136/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8618 - val_loss: 0.8662\n",
      "Epoch 137/200\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8673 - val_loss: 0.8662\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "autoencoder.fit(S_X_train, S_X_train, epochs=200, batch_size=128, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Reconstruction error on training data\n",
    "reconstructions = autoencoder.predict(S_X_train)\n",
    "reconstruction_errors = np.mean(np.square(S_X_train - reconstructions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABOQUlEQVR4nO3deVgVZf8G8PsAnsOOILIpAuIuioYbuWGiqGhqtrgFGmq+Qqa4pGmuvZKWS/WaVC5Y5pJmZuqr4J5KlgSaqOSOC6Cisin78/vDH/N6BBQOBw6HuT/XdS49M8/MfGcY4OaZZ+YohBACRERERDJmoOsCiIiIiHSNgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiEgHDh8+DIVCgcOHD+u6lBrr2rVrUCgUiIiIqPRtRUREQKFQ4Nq1a9I0V1dX9O/fv9K3Dej+fCosLISHhwf+/e9/V+l2R40aBVdXV42WnTdvHhQKhXYLqgFSU1NhZmaGPXv26LqUKsdAJCNFP7SLXkZGRqhXrx5GjRqFW7du6bo8rfvqq6+q5Jdhda/hWT4+PmrnwdOvZs2a6bq8Uj177trY2MDLywvvv/8+zp07p7XtVMevWZHqWtumTZtw48YNhISEAECp59ezL7n+QTBq1Ci142Bubo6GDRvi9ddfx08//YTCwkKN171x40asWLFC4+Xr1KmDMWPG4KOPPtJ4HfpKwc8yk4+IiAiMHj0aCxYsgJubG7Kzs/H7778jIiICrq6uOHv2LIyNjXVdptZ4eHjA1tZWpz90S6uhsLAQubm5UCqVMDCo2r9LfHx8cPnyZYSFhRWbZ2VlhQEDBlRpPWWlUCjQq1cvBAQEQAiBtLQ0nD59Glu3bkVWVhYWL16M0NBQqb0QAjk5OahVqxYMDQ3LvB1NzpuCggLk5eVBpVJJvQ6urq7w8PDArl27yrweTWvT5fkEAG3atEHHjh3x9ddfAwA2bNigNv+7775DVFQUvv/+e7XpvXr1gr29vcbbzcvLQ2FhIVQqVbmXzc/PR35+vk5+5o0aNQqbN2/G6tWrAQCPHz/G9evX8euvv+LMmTPw8fHBL7/8AktLy3Kvu3///jh79qxab2V5nT9/Hi1atMCBAwfwyiuvaLwefWOk6wKo6vXt2xft2rUDAIwZMwa2trZYvHgxdu7ciTfffFPH1elGVlYWzMzMqmx7BgYGOg2fVlZWGDlyZLmXK+04CSGQnZ0NExMTjWvKzs5+4S/0Jk2aFKv7k08+wYABAzBlyhQ0a9YM/fr1A/AkQFX2MS46HoaGhuUKXdqmy/MpNjYWp0+fxtKlS6Vpz36Nfv/9d0RFRb3wnHv06BFMTU3LvO1atWqVr9inGBkZwchId78CjYyMih2Pjz/+GJ988glmzpyJsWPHYsuWLTqprXnz5vDw8EBERISsAhEvmRG6du0KALh8+bLa9AsXLuD111+HjY0NjI2N0a5dO+zcubPY8g8fPsTkyZPh6uoKlUqF+vXrIyAgAPfu3ZPa3LlzB0FBQbC3t4exsTE8PT2xfv16tfUUjfn47LPP8M0338Dd3R0qlQrt27fHn3/+qdY2OTkZo0ePRv369aFSqeDo6IiBAwdKfxW5uroiPj4eR44ckbqlfXx8APzv0uGRI0cwYcIE2NnZoX79+gBKH5NQ2niDDRs2oEOHDjA1NYW1tTW6deuGyMjIF9ZQ2piPrVu3wsvLCyYmJrC1tcXIkSOLXc4cNWoUzM3NcevWLQwaNAjm5uaoW7cupk6dioKCgmI1aqpon8+dO4fhw4fD2toaXbp0kfatf//+2LdvH9q1awcTExOpd+DKlSt44403YGNjA1NTU3Tq1Am7d+9WW3fR/m/evBmzZ89GvXr1YGpqivT09HLXWadOHWzevBlGRkZqY1hKGkNUWedNSWOIikRGRqJNmzYwNjZGixYtsH379hKP87OeXWd1PZ927NgBpVKJbt26vbDt03x8fODh4YGYmBh069YNpqam+PDDDwEAv/zyC/z9/eHk5ASVSgV3d3csXLiwWD3Pfr+W52dIScddoVAgJCQEO3bsgIeHB1QqFVq2bIm9e/cWq//w4cNo164djI2N4e7ujq+//lor45JmzJiB3r17Y+vWrfjnn3+k6WU5Jj4+Pti9ezeuX78unSNFxyc3Nxdz5syBl5cXrKysYGZmhq5du+LQoUMl1tGrVy/8+uuvkNNFJPYQkfQD19raWpoWHx+Pzp07o169epgxYwbMzMzw448/YtCgQfjpp58wePBgAEBmZia6du2K8+fP45133sFLL72Ee/fuYefOnbh58yZsbW3x+PFj+Pj44NKlSwgJCYGbmxu2bt2KUaNG4eHDh3j//ffV6tm4cSMyMjLw7rvvQqFQYMmSJXjttddw5coV6S/CIUOGID4+Hu+99x5cXV1x584dREVFITExEa6urlixYgXee+89mJubY9asWQBQrGt+woQJqFu3LubMmYOsrKxyH7f58+dj3rx5ePnll7FgwQIolUqcPHkSBw8eRO/evctUw9OKLmm2b98eYWFhSElJweeff47jx48jNjYWtWvXltoWFBTAz88PHTt2xGeffYb9+/dj6dKlcHd3x7/+9a8X1l5QUKAWWIuYmJgU6wF644030LhxYyxatEjth2NCQgKGDRuGd999F2PHjkXTpk2RkpKCl19+GY8ePcLEiRNRp04drF+/Hq+++iq2bdsmnTdFFi5cCKVSialTpyInJwdKpfKFtZekQYMG6N69Ow4dOoT09PRSLzVU9Xlz8eJFvPXWWxg/fjwCAwOxbt06vPHGG9i7dy969epVrn2srufTiRMn4OHhoVFvTWpqKvr27YuhQ4di5MiR0v5ERETA3NwcoaGhMDc3x8GDBzFnzhykp6fj008/feF6y/IzpDTHjh3D9u3bMWHCBFhYWOCLL77AkCFDkJiYiDp16gB40ivWp08fODo6Yv78+SgoKMCCBQtQt27dch+Dkrz99tuIjIxEVFQUmjRpAqBsx2TWrFlIS0vDzZs3sXz5cgCAubk5ACA9PR2rV6/GsGHDMHbsWGRkZGDNmjXw8/PDH3/8gTZt2qjV4OXlheXLlyM+Ph4eHh5a2a9qT5BsrFu3TgAQ+/fvF3fv3hU3btwQ27ZtE3Xr1hUqlUrcuHFDatuzZ0/RqlUrkZ2dLU0rLCwUL7/8smjcuLE0bc6cOQKA2L59e7HtFRYWCiGEWLFihQAgNmzYIM3Lzc0V3t7ewtzcXKSnpwshhLh69aoAIOrUqSPu378vtf3ll18EAPHrr78KIYR48OCBACA+/fTT5+5vy5YtRffu3Us9Dl26dBH5+flq8wIDA4WLi0uxZebOnSue/na5ePGiMDAwEIMHDxYFBQUl7vfzajh06JAAIA4dOiQdDzs7O+Hh4SEeP34stdu1a5cAIObMmaNWIwCxYMECtXW2bdtWeHl5FdvWs7p37y4AlPh69913i+3zsGHDiq3DxcVFABB79+5Vmz5p0iQBQPz222/StIyMDOHm5iZcXV2lY1W0/w0bNhSPHj16Yc1CCAFABAcHlzr//fffFwDE6dOnhRD/O5/WrVsnhKjc86Zo3tWrV6VpRcfop59+kqalpaUJR0dH0bZtW2nas+fW89ZZHc+n+vXriyFDhjy3TXBwcLF9LDoPw8PDi7Uv6Zx49913hampqdrPpGe/X8v6M0SIko87AKFUKsWlS5ekaadPnxYAxJdffilNGzBggDA1NRW3bt2Spl28eFEYGRmV+LV8VmBgoDAzMyt1fmxsrAAgJk+eLE0r6zHx9/cv8WdYfn6+yMnJUZv24MEDYW9vL955551i7U+cOCEAiC1btrxwf2oKXjKTIV9fX9StWxfOzs54/fXXYWZmhp07d0rd//fv38fBgwfx5ptvIiMjA/fu3cO9e/eQmpoKPz8/XLx4Uep2/+mnn+Dp6VnsL38AUtfxnj174ODggGHDhknzatWqhYkTJyIzMxNHjhxRW+6tt95S660quqR35coVAE96MZRKJQ4fPowHDx5ofBzGjh2r8biPHTt2oLCwEHPmzCk25kWTLvNTp07hzp07mDBhgtpYEH9/fzRr1qzYJScAGD9+vNr7rl27SsfoRVxdXREVFVXsNWnSpBdup4ibmxv8/PzUpu3ZswcdOnSQLq0BT/5CHTduHK5du1bsbrDAwMAKjTt6WtFfwhkZGSXO18V54+TkpPa9YWlpiYCAAMTGxiI5OVnjGl6kKs+n1NRUte/X8lCpVBg9enSx6U+fE0U/g7p27YpHjx7hwoULL1zvi36GPI+vry/c3d2l961bt4alpaW0bEFBAfbv349BgwbByclJateoUSP07dv3hesvi5LO5YoeE0NDQ6kHtrCwEPfv30d+fj7atWuHv/76q1j7ouNXUk9yTcVLZjK0cuVKNGnSBGlpaVi7di2OHj2qdpfGpUuXIITARx99VOqtl3fu3EG9evVw+fJlDBky5Lnbu379Oho3blwsODRv3lya/7QGDRqovS/6xiz6JaZSqbB48WJMmTIF9vb26NSpE/r374+AgAA4ODiU4Qg84ebmVua2z7p8+TIMDAzQokULjdfxtKJj0LRp02LzmjVrhmPHjqlNMzY2LtY9b21tXeZf9GZmZvD19S1T29KOU0nTr1+/jo4dOxab/vTX+unu94p8DZ6VmZkJALCwsChxvi7Om0aNGhULyEWXQK5du1au7ZZHVZ9PQsNxJvXq1SvxMml8fDxmz56NgwcPFhtXlpaW9sL1vuhnSHmWLVq+aNk7d+7g8ePHaNSoUbF2JU3TREnnckWPCQCsX78eS5cuxYULF5CXlydNL+mcLvqayulZTQxEMtShQwfpLrNBgwahS5cuGD58OBISEmBubi49A2Pq1KnFegCKaOsbvySl/fX99A/dSZMmYcCAAdixYwf27duHjz76CGFhYTh48CDatm1bpu2U1DNR2je/Ngcra0NV3tFUWg+ONnp2tNU7BABnz56FoaHhcwNLZZ03FVEdzrmKnE916tTRuMetpGP58OFDdO/eHZaWlliwYAHc3d1hbGyMv/76Cx988EGZntFTlp8hlbGstpw9exbA/37OauOYbNiwAaNGjcKgQYMwbdo02NnZwdDQEGFhYcVuqAH+Fx5tbW21uGfVGwORzBV9Q/To0QP/+c9/MGPGDDRs2BDAk8taL+pFcHd3l755S+Pi4oIzZ86gsLBQrZeoqJvXxcVFo9rd3d0xZcoUTJkyBRcvXkSbNm2wdOlS6RkomvxlY21tjYcPHxab/mwvlru7OwoLC3Hu3LligxGfVtYaio5BQkJCsdtcExISND5GVc3FxQUJCQnFplf0a/0iiYmJOHLkCLy9vUvtISpSGedNaYp6W59eZ9GdQ0V3/xT1Xjx8+FBtoPOz51x5aqvK86lZs2a4evWq1tZ3+PBhpKamYvv27Wp3rmlzGxVhZ2cHY2NjXLp0qdi8kqZp4vvvv5eeuwWU75iUdo5s27YNDRs2xPbt29XazJ07t8T2Resu6t2VA44hIvj4+KBDhw5YsWIFsrOzYWdnBx8fH3z99ddISkoq1v7u3bvS/4cMGYLTp0/j559/Ltau6C+qfv36ITk5We2ZGvn5+fjyyy9hbm6O7t27l6veR48eITs7W22au7s7LCwskJOTI00zMzMrMdw8j7u7O9LS0nDmzBlpWlJSUrH9GzRoEAwMDLBgwYJif509/ZdkWWto164d7OzsEB4errYP//3vf3H+/Hn4+/uXaz90pV+/fvjjjz8QHR0tTcvKysI333wDV1dXrV1ifNr9+/cxbNgwFBQUSHdflaQyz5vS3L59W+3cSU9Px3fffYc2bdpIl8uKxqscPXpUapeVlVXssRTlqa0qzydvb2+cPXtWbTsVUdRD8/T3UW5uLr766iutrL+iDA0N4evrix07duD27dvS9EuXLuG///1vhdf/ySefIDIyEm+99RYaN24sbRMo2zExMzMr8RJaSes4efKk2vfq02JiYmBlZYWWLVtqvjN6hj1EBACYNm0a3njjDURERGD8+PFYuXIlunTpglatWmHs2LFo2LAhUlJSEB0djZs3b+L06dPSctu2bcMbb7yBd955B15eXrh//z527tyJ8PBweHp6Yty4cfj6668xatQoxMTEwNXVFdu2bcPx48exYsWKF/5F/6x//vkHPXv2xJtvvokWLVrAyMgIP//8M1JSUjB06FCpnZeXF1atWoWPP/4YjRo1gp2d3QsfMjZ06FB88MEHGDx4MCZOnIhHjx5h1apVaNKkidrAw0aNGmHWrFlYuHAhunbtitdeew0qlQp//vknnJycpKdAl7WGWrVqYfHixRg9ejS6d++OYcOGSbdJu7q6YvLkyeU6Ri+SlpZW7GnCRTR5YGORGTNmYNOmTejbty8mTpwIGxsbrF+/HlevXsVPP/1U4aco//PPP9iwYQOEEEhPT5eeVJ2ZmYlly5ahT58+z122ss6b0jRp0gRBQUH4888/YW9vj7Vr1yIlJQXr1q2T2vTu3RsNGjRAUFAQpk2bBkNDQ6xduxZ169ZFYmKi2vqq4/k0cOBALFy4EEeOHEHv3r0rvL6XX34Z1tbWCAwMxMSJE6FQKPD9999Xq+fhzJs3D5GRkejcuTP+9a9/oaCgAP/5z3/g4eGBuLi4Mq0jPz9f+h7Mzs7G9evXsXPnTpw5cwY9evTAN998I7UtzzHx8vLCli1bEBoaivbt28Pc3BwDBgxA//79sX37dgwePBj+/v64evUqwsPD0aJFC2nM0tOioqIwYMAAWY0h4m33MlJ0G++ff/5ZbF5BQYFwd3cX7u7u0i3Fly9fFgEBAcLBwUHUqlVL1KtXT/Tv319s27ZNbdnU1FQREhIi6tWrJ5RKpahfv74IDAwU9+7dk9qkpKSI0aNHC1tbW6FUKkWrVq2k26GLFN0yW9Jt0QDE3LlzhRBC3Lt3TwQHB4tmzZoJMzMzYWVlJTp27Ch+/PFHtWWSk5OFv7+/sLCwEACk25WfdxyEECIyMlJ4eHgIpVIpmjZtKjZs2FDqrdFr164Vbdu2FSqVSlhbW4vu3buLqKioF9bw7G3SRbZs2SKtz8bGRowYMULcvHlTrU1pt+yWVuOznnfb/dPLF63v7t27xdbh4uIi/P39S1z/5cuXxeuvvy5q164tjI2NRYcOHcSuXbvU2hTt/9atW19Yb5GnazQwMBC1a9cWbdu2Fe+//76Ij48v1v7Z2+4r87wp7bZ7f39/sW/fPtG6dWuhUqlEs2bNStznmJgY0bFjR6FUKkWDBg3EsmXLSlxndTyfhBCidevWIigoqNT5pd1237JlyxLbHz9+XHTq1EmYmJgIJycnMX36dLFv375i+1jabfcv+hlS2v6hlEc7uLi4iMDAQLVpBw4cEG3bthVKpVK4u7uL1atXiylTpghjY+NSjsL/FD3qoOhlamoqXF1dxZAhQ8S2bduKPcqjPMckMzNTDB8+XNSuXVsAkI5PYWGhWLRokXBxcREqlUq0bdtW7Nq1q8RHjZw/f156RIuc8LPMiIioQr7//nsEBwcjMTFRbRyU3AwaNAjx8fG4ePGirkupkEmTJuHo0aOIiYmRVQ8RxxAREVGFjBgxAg0aNMDKlSt1XUqVefz4sdr7ixcvYs+ePdLHqeir1NRUrF69Gh9//LGswhDAT7snIiIqN0dHR4waNQoNGzbE9evXsWrVKuTk5CA2NlYaDE36hYOqiYiIyqlPnz7YtGkTkpOToVKp4O3tjUWLFjEM6TH2EBEREZHscQwRERERyR4DEREREckexxCVQWFhIW7fvg0LCwvZjbonIiLSV0IIZGRkwMnJ6YUPhmUgKoPbt2/D2dlZ12UQERGRBm7cuIH69es/tw0DURkUfbTEjRs3YGlpqeNqiIiIADRrBiQlAY6OwP9/gDKpS09Ph7Ozc5k+IoqBqAyKLpNZWloyEBERUfUwbx6QmQmYmwP83fRcZRnuwkBERESkj8aN03UFNQrvMiMiIiLZYyAiIiIi2eMlMyIiIn2UlAQUFACGhk8GVlOFsIeIiIhIH7VvDzg7P/mXKoyBiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI8f3UFERKSPDhwA8vMBI/4q1wYeRZlxnbH7hW2ufeJfBZUQEVGFNG2q6wpqFF4yIyIiItljICIiIiLZ4yUzIiIifbRxI/DoEWBqCgwfrutq9B4DkZ7g2B8iIlIzfTpw6xZQrx4DkRbwkhkRERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4fzEhERKSPHBzU/6UKYSAiIiLSR6dO6bqCGoWXzIiIiEj2GIiIiIhI9hiIiIiISPZ0GojCwsLQvn17WFhYwM7ODoMGDUJCQoJaGx8fHygUCrXX+PHj1dokJibC398fpqamsLOzw7Rp05Cfn6/W5vDhw3jppZegUqnQqFEjREREVPbuERERVZ533wXeeOPJv1RhOh1UfeTIEQQHB6N9+/bIz8/Hhx9+iN69e+PcuXMwMzOT2o0dOxYLFiyQ3puamkr/LygogL+/PxwcHHDixAkkJSUhICAAtWrVwqJFiwAAV69ehb+/P8aPH48ffvgBBw4cwJgxY+Do6Ag/P7+q22EiIiJt2b0buHULqFdP15XUCDoNRHv37lV7HxERATs7O8TExKBbt27SdFNTUziUclthZGQkzp07h/3798Pe3h5t2rTBwoUL8cEHH2DevHlQKpUIDw+Hm5sbli5dCgBo3rw5jh07huXLlzMQERERUfUaQ5SWlgYAsLGxUZv+ww8/wNbWFh4eHpg5cyYePXokzYuOjkarVq1gb28vTfPz80N6ejri4+OlNr6+vmrr9PPzQ3R0dGXtChEREemRavMcosLCQkyaNAmdO3eGh4eHNH348OFwcXGBk5MTzpw5gw8++AAJCQnYvn07ACA5OVktDAGQ3icnJz+3TXp6Oh4/fgwTExO1eTk5OcjJyZHep6ena29HiYiIqNqpNoEoODgYZ8+exbFjx9Smjxs3Tvp/q1at4OjoiJ49e+Ly5ctwd3evlFrCwsIwf/78Slk3ERERVT/V4pJZSEgIdu3ahUOHDqF+/frPbduxY0cAwKVLlwAADg4OSElJUWtT9L5o3FFpbSwtLYv1DgHAzJkzkZaWJr1u3Lih2Y4RERGRXtBpIBJCICQkBD///DMOHjwINze3Fy4TFxcHAHB0dAQAeHt74++//8adO3ekNlFRUbC0tESLFi2kNgcOHFBbT1RUFLy9vUvchkqlgqWlpdqLiIiIai6dBqLg4GBs2LABGzduhIWFBZKTk5GcnIzHjx8DAC5fvoyFCxciJiYG165dw86dOxEQEIBu3bqhdevWAIDevXujRYsWePvtt3H69Gns27cPs2fPRnBwMFQqFQBg/PjxuHLlCqZPn44LFy7gq6++wo8//ojJkyfrbN+JiIio+tBpIFq1ahXS0tLg4+MDR0dH6bVlyxYAgFKpxP79+9G7d280a9YMU6ZMwZAhQ/Drr79K6zA0NMSuXbtgaGgIb29vjBw5EgEBAWrPLXJzc8Pu3bsRFRUFT09PLF26FKtXr+Yt90RERARAx4OqhRDPne/s7IwjR468cD0uLi7Ys2fPc9v4+PggNja2XPURERFVW8OGAQ8eANbWuq6kRqg2d5kRERFROXz6qa4rqFGqxV1mRERERLrEQERERESyx0BEREREssdAREREpI+aNQMsLZ/8SxXGQERERKSPMjOBjIwn/1KFMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkezx0+6JiIj0UXg48PgxYGKi60pqBAYiIiIifdS/v64rqFF4yYyIiIhkj4GIiIiIZI+XzIiIiPRRTAyQmwsolYCXl66r0XsMRERERPpo4EDg1i2gXj3g5k1dV6P3eMmMiIiIZI+BiIiIiGSPl8yIiIhkyHXG7he2ufaJfxVUUj2wh4iIiIhkj4GIiIiIZI+XzIiIiGqYslwOI3XsISIiIiLZYyAiIiIi2WMgIiIiItnjGCIiIiJ9dP48IASgUOi6khqBgYiIiEgfWVjouoIahZfMiIiISPYYiIiIiEj2eMmMiIhIHy1bBqSnA5aWQGiorqvRewxERERE+mjZMuDWLaBePQYiLeAlMyIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPT6YkYiISB+99BLg7AzUravrSmoEBiIiIiJ9tHOnriuoUXjJjIiIiGSPgYiIiIhkj4GIiIiIZI9jiIiIiPTRq68Cd+8+GVTN8UQVxkBERESkj/76C7h1C6hXT9eV1Ai8ZEZERESyx0BEREREssdARERERLLHQERERESyx0BEREREsqfTQBQWFob27dvDwsICdnZ2GDRoEBISEtTaZGdnIzg4GHXq1IG5uTmGDBmClJQUtTaJiYnw9/eHqakp7OzsMG3aNOTn56u1OXz4MF566SWoVCo0atQIERERlb17REREpCd0GoiOHDmC4OBg/P7774iKikJeXh569+6NrKwsqc3kyZPx66+/YuvWrThy5Ahu376N1157TZpfUFAAf39/5Obm4sSJE1i/fj0iIiIwZ84cqc3Vq1fh7++PHj16IC4uDpMmTcKYMWOwb9++Kt1fIiIiqp50+hyivXv3qr2PiIiAnZ0dYmJi0K1bN6SlpWHNmjXYuHEjXnnlFQDAunXr0Lx5c/z+++/o1KkTIiMjce7cOezfvx/29vZo06YNFi5ciA8++ADz5s2DUqlEeHg43NzcsHTpUgBA8+bNcezYMSxfvhx+fn5Vvt9ERERUvVSrMURpaWkAABsbGwBATEwM8vLy4OvrK7Vp1qwZGjRogOjoaABAdHQ0WrVqBXt7e6mNn58f0tPTER8fL7V5eh1FbYrWQUREpHdCQ4G5c5/8SxVWbZ5UXVhYiEmTJqFz587w8PAAACQnJ0OpVKJ27dpqbe3t7ZGcnCy1eToMFc0vmve8Nunp6Xj8+DFMTEzU5uXk5CAnJ0d6n56eXvEdJCIi0iYGIa2qNj1EwcHBOHv2LDZv3qzrUhAWFgYrKyvp5ezsrOuSiIiIqBJVi0AUEhKCXbt24dChQ6hfv7403cHBAbm5uXj48KFa+5SUFDg4OEhtnr3rrOj9i9pYWloW6x0CgJkzZyItLU163bhxo8L7SERERNWXTgOREAIhISH4+eefcfDgQbi5uanN9/LyQq1atXDgwAFpWkJCAhITE+Ht7Q0A8Pb2xt9//407d+5IbaKiomBpaYkWLVpIbZ5eR1GbonU8S6VSwdLSUu1FRERUrWRkAOnpT/6lCtNpIAoODsaGDRuwceNGWFhYIDk5GcnJyXj8+DEAwMrKCkFBQQgNDcWhQ4cQExOD0aNHw9vbG506dQIA9O7dGy1atMDbb7+N06dPY9++fZg9ezaCg4OhUqkAAOPHj8eVK1cwffp0XLhwAV999RV+/PFHTJ48WWf7TkREVCHNmwNWVk/+pQrTaSBatWoV0tLS4OPjA0dHR+m1ZcsWqc3y5cvRv39/DBkyBN26dYODgwO2b98uzTc0NMSuXbtgaGgIb29vjBw5EgEBAViwYIHUxs3NDbt370ZUVBQ8PT2xdOlSrF69mrfcExEREQAd32UmhHhhG2NjY6xcuRIrV64stY2Liwv27Nnz3PX4+PggNja23DUSERFRzVctBlUTERER6RIDEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyV61+bR7IiIiKodffgFycwGlUteV1AgMRERERPrIy0vXFdQovGRGREREssdARERERLLHS2ZERET6aNcu4PFjwMQE6N9f19XoPQYiIiIifTR+PHDrFlCvHnDzpq6r0Xu8ZEZERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdAREREpI/MzQELiyf/UoXxSdVERET66MIFXVdQo7CHiIiIiGSPgYiIiIhkj4GIiIiIZI9jiIiIiPTRtGnAgweAtTXw6ae6rkbvMRARERHpo02bgFu3gHr1GIi0gJfMiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2+GBGIiIifeTvD9y/D9jY6LqSGoGBiIiISB99/bWuK6hReMmMiIiIZE+jQHTlyhVt10FERESkMxoFokaNGqFHjx7YsGEDsrOztV0TERERUZXSKBD99ddfaN26NUJDQ+Hg4IB3330Xf/zxh7ZrIyIiotK0awfUr//kX6owjQJRmzZt8Pnnn+P27dtYu3YtkpKS0KVLF3h4eGDZsmW4e/eutuskIiKipyUnA7duPfmXKqxCg6qNjIzw2muvYevWrVi8eDEuXbqEqVOnwtnZGQEBAUhKStJWnURERESVpkKB6NSpU5gwYQIcHR2xbNkyTJ06FZcvX0ZUVBRu376NgQMHaqtOIiIiokqj0XOIli1bhnXr1iEhIQH9+vXDd999h379+sHA4Em+cnNzQ0REBFxdXbVZKxEREVGl0CgQrVq1Cu+88w5GjRoFR0fHEtvY2dlhzZo1FSqOysd1xm5dl0BERKSXNApEFy9efGEbpVKJwMBATVZPREREVKU0GkO0bt06bN26tdj0rVu3Yv369RUuioiIiKgqaRSIwsLCYGtrW2y6nZ0dFi1aVOGiiIiIiKqSRoEoMTERbm5uxaa7uLggMTGxwkURERERVSWNxhDZ2dnhzJkzxe4iO336NOrUqaONuoiIiOh5liwBHj0CTE11XUmNoFEgGjZsGCZOnAgLCwt069YNAHDkyBG8//77GDp0qFYLJCIiov/53x3FVv//AnCGdxlXlEaBaOHChbh27Rp69uwJI6MnqygsLERAQADHEBEREZHe0SgQKZVKbNmyBQsXLsTp06dhYmKCVq1awcXFRdv1EREREVW6Cn10R5MmTfDGG2+gf//+GoWho0ePYsCAAXBycoJCocCOHTvU5o8aNQoKhULt1adPH7U29+/fx4gRI2BpaYnatWsjKCgImZmZam3OnDmDrl27wtjYGM7OzliyZEm5ayUiIqpOGqbeROO719Ew9aauS6kRNOohKigoQEREBA4cOIA7d+6gsLBQbf7BgwfLtJ6srCx4enrinXfewWuvvVZimz59+mDdunXSe5VKpTZ/xIgRSEpKQlRUFPLy8jB69GiMGzcOGzduBACkp6ejd+/e8PX1RXh4OP7++2+88847qF27NsaNG1ee3SYiIqo2ftg8C46ZqUgyrwPvYD4DsKI0CkTvv/8+IiIi4O/vDw8PDygUCo023rdvX/Tt2/e5bVQqFRwcHEqcd/78eezduxd//vkn2rVrBwD48ssv0a9fP3z22WdwcnLCDz/8gNzcXKxduxZKpRItW7ZEXFwcli1bxkBEREREADQMRJs3b8aPP/6Ifv36abueYg4fPgw7OztYW1vjlVdewccffyzd2h8dHY3atWtLYQgAfH19YWBggJMnT2Lw4MGIjo5Gt27doFQqpTZ+fn5YvHgxHjx4AGtr62LbzMnJQU5OjvQ+PT29EveQiIiIdE2jMURKpRKNGjXSdi3F9OnTB9999x0OHDiAxYsX48iRI+jbty8KCgoAAMnJybCzs1NbxsjICDY2NkhOTpba2Nvbq7Upel/U5llhYWGwsrKSXs7OztreNSIiIqpGNApEU6ZMweeffw4hhLbrUTN06FC8+uqraNWqFQYNGoRdu3bhzz//xOHDhyt1uzNnzkRaWpr0unHjRqVuj4iIiHRLo0tmx44dw6FDh/Df//4XLVu2RK1atdTmb9++XSvFPathw4awtbXFpUuX0LNnTzg4OODOnTtqbfLz83H//n1p3JGDgwNSUlLU2hS9L21skkqlKjZ4m4iIiGoujQJR7dq1MXjwYG3X8kI3b95EamoqHB0dAQDe3t54+PAhYmJi4OXlBeDJHW6FhYXo2LGj1GbWrFnIy8uTgltUVBSaNm1a4vghIiIikh+NAtHTt8FXRGZmJi5duiS9v3r1KuLi4mBjYwMbGxvMnz8fQ4YMgYODAy5fvozp06ejUaNG8PPzAwA0b94cffr0wdixYxEeHo68vDyEhIRg6NChcHJyAgAMHz4c8+fPR1BQED744AOcPXsWn3/+OZYvX66VfSAiIiL9p/GDGfPz87F//358/fXXyMjIAADcvn272EMRn+fUqVNo27Yt2rZtCwAIDQ1F27ZtMWfOHBgaGuLMmTN49dVX0aRJEwQFBcHLywu//fab2uWsH374Ac2aNUPPnj3Rr18/dOnSBd98840038rKCpGRkbh69Sq8vLwwZcoUzJkzh7fcExERkUSjHqLr16+jT58+SExMRE5ODnr16gULCwssXrwYOTk5CA8PL9N6fHx8njswe9++fS9ch42NjfQQxtK0bt0av/32W5lqIiIiIvnR+MGM7dq1w+nTp6VnAgHA4MGDMXbsWK0VR0RERCV7NXA5DAsLUWBQoU/hov+nUSD67bffcOLECbWHHQKAq6srbt26pZXCiIiIqHR3zW10XUKNolGsLCwslB6O+LSbN2/CwsKiwkURERERVSWNAlHv3r2xYsUK6b1CoUBmZibmzp1bJR/nQURERKRNGl0yW7p0Kfz8/NCiRQtkZ2dj+PDhuHjxImxtbbFp0yZt10hERETPGBa3F6a5j/FIaYJNbfrouhy9p1Egql+/Pk6fPo3NmzfjzJkzyMzMRFBQEEaMGAETExNt10hERETPmHh8ExwzU5FkXoeBSAs0CkTAkw9RHTlypDZrISIikjXXGbt1XYJsaRSIvvvuu+fODwgI0KgYIiIiIl3Q+DlET8vLy8OjR4+gVCphamrKQERERER6RaO7zB48eKD2yszMREJCArp06cJB1URERKR3tPZ4y8aNG+OTTz4p1ntEREREVN1p9XnfRkZGuH37tjZXSURERFTpNBpDtHPnTrX3QggkJSXhP//5Dzp37qyVwoiIiIiqikaBaNCgQWrvFQoF6tati1deeQVLly7VRl1EREREVUajQFRYWKjtOoiIiKgcrtrUQ4bKDPfMauu6lBpB4wczEhERke4MH7ZI1yXUKBoFotDQ0DK3XbZsmSabICIiIqoyGgWi2NhYxMbGIi8vD02bNgUA/PPPPzA0NMRLL70ktVMoFNqpkoiIiKgSaRSIBgwYAAsLC6xfvx7W1tYAnjyscfTo0ejatSumTJmi1SKJiIiIKpNGgWjp0qWIjIyUwhAAWFtb4+OPP0bv3r0ZiIiIiCrZil8/hc2jdNw3tcSkAdN0XY7e0ygQpaen4+7du8Wm3717FxkZGRUuioiIiJ6vY+JZOGamIsm8jq5LqRE0elL14MGDMXr0aGzfvh03b97EzZs38dNPPyEoKAivvfaatmskIiIiqlQa9RCFh4dj6tSpGD58OPLy8p6syMgIQUFB+PTTT7VaIBEREVFl0ygQmZqa4quvvsKnn36Ky5cvAwDc3d1hZmam1eKIiIiIqkKFPtw1KSkJSUlJaNy4MczMzCCE0FZdRERERFVGo0CUmpqKnj17okmTJujXrx+SkpIAAEFBQbzDjIiIiPSORoFo8uTJqFWrFhITE2FqaipNf+utt7B3716tFUdERERUFTQaQxQZGYl9+/ahfv36atMbN26M69eva6UwIiIioqqiUSDKyspS6xkqcv/+fahUqgoXRURERLrnOmP3C9tc+8S/CiqpfBpdMuvatSu+++476b1CoUBhYSGWLFmCHj16aK04IiIiKtlmTz+sbjcQmz39dF1KjaBRD9GSJUvQs2dPnDp1Crm5uZg+fTri4+Nx//59HD9+XNs1EhER0TM+7zJc1yXUKBr1EHl4eOCff/5Bly5dMHDgQGRlZeG1115DbGws3N3dtV0jERERUaUqdw9RXl4e+vTpg/DwcMyaNasyaiIiIiKqUuXuIapVqxbOnDlTGbUQERER6YRGl8xGjhyJNWvWaLsWIiIiKqPolYG4trg/olcG6rqUGkGjQdX5+flYu3Yt9u/fDy8vr2KfYbZs2TKtFEdERERUFcoViK5cuQJXV1ecPXsWL730EgDgn3/+UWujUCi0Vx0RERFRFShXIGrcuDGSkpJw6NAhAE8+quOLL76Avb19pRRHRERUU5TlIYekO+UaQ/Tsp9n/97//RVZWllYLIiIiIqpqGg2qLvJsQCIiIiLSR+UKRAqFotgYIY4ZIiIiIn1XrjFEQgiMGjVK+gDX7OxsjB8/vthdZtu3b9dehURERESVrFyBKDBQ/VkHI0eO1GoxRERERLpQrkC0bt26yqqDiIiISGc0ejAjERER6dbkAVOgzM9DrlEtXZdSIzAQERER6aHfG7TWdQk1CgMRFVOWh4dd+8S/CiohIiKqGhV6DhERERFRTcAeIiIiIj3UKfGMNIaIl88qjoGIiIhIDy3/dSkcM1ORZF4H3sHrdV2O3uMlMyIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPZ0GoqNHj2LAgAFwcnKCQqHAjh071OYLITBnzhw4OjrCxMQEvr6+uHjxolqb+/fvY8SIEbC0tETt2rURFBSEzMxMtTZnzpxB165dYWxsDGdnZyxZsqSyd42IiIj0iE4DUVZWFjw9PbFy5coS5y9ZsgRffPEFwsPDcfLkSZiZmcHPzw/Z2dlSmxEjRiA+Ph5RUVHYtWsXjh49inHjxknz09PT0bt3b7i4uCAmJgaffvop5s2bh2+++abS94+IiIj0g06fQ9S3b1/07du3xHlCCKxYsQKzZ8/GwIEDAQDfffcd7O3tsWPHDgwdOhTnz5/H3r178eeff6Jdu3YAgC+//BL9+vXDZ599BicnJ/zwww/Izc3F2rVroVQq0bJlS8TFxWHZsmVqwYmIiIjkq9qOIbp69SqSk5Ph6+srTbOyskLHjh0RHR0NAIiOjkbt2rWlMAQAvr6+MDAwwMmTJ6U23bp1g1KplNr4+fkhISEBDx48KHHbOTk5SE9PV3sRERFRzVVtn1SdnJwMALC3t1ebbm9vL81LTk6GnZ2d2nwjIyPY2NiotXFzcyu2jqJ51tbWxbYdFhaG+fPna2dHiIiIKgGfTq1d1baHSJdmzpyJtLQ06XXjxg1dl0RERESVqNoGIgcHBwBASkqK2vSUlBRpnoODA+7cuaM2Pz8/H/fv31drU9I6nt7Gs1QqFSwtLdVeREREVHNV20Dk5uYGBwcHHDhwQJqWnp6OkydPwtvbGwDg7e2Nhw8fIiYmRmpz8OBBFBYWomPHjlKbo0ePIi8vT2oTFRWFpk2blni5jIiIiORHp4EoMzMTcXFxiIuLA/BkIHVcXBwSExOhUCgwadIkfPzxx9i5cyf+/vtvBAQEwMnJCYMGDQIANG/eHH369MHYsWPxxx9/4Pjx4wgJCcHQoUPh5OQEABg+fDiUSiWCgoIQHx+PLVu24PPPP0doaKiO9pqIiKji3j+2EbMPfIv3j23UdSk1gk4HVZ86dQo9evSQ3heFlMDAQERERGD69OnIysrCuHHj8PDhQ3Tp0gV79+6FsbGxtMwPP/yAkJAQ9OzZEwYGBhgyZAi++OILab6VlRUiIyMRHBwMLy8v2NraYs6cObzlnoiI9NrQ0/vgmJmKJPM6+LzLcF2Xo/d0Goh8fHwghCh1vkKhwIIFC7BgwYJS29jY2GDjxuen49atW+O3337TuE4iIiKq2artGCIiIiKiqsJARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREsldtP+2eiIiISneygQdsHqXjvik/b1MbGIiIiIj00KQB03RdQo3CS2ZEREQkewxEREREJHsMRERERCR7HENERESkhzZu+hC2WQ9xz6w2hg9bpOty9B4DERERkR5yu38LjpmpsMjJ0nUpNQIvmREREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7PHBjERERHroi87DYJr7GI+UJroupUZgICIiItJDm9r00XUJNQovmREREZHsMRARERGR7PGSGRERkR6qm3kfhoWFKDAwwF1zG12Xo/cYiIiIiPTQzvWT4ZiZiiTzOvAOXq/rcvQeL5kRERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHs8UnVREREemjE0H/DsLAABQaGui6lRmAgIiIi0kNX6tTXdQk1Ci+ZERERkewxEBEREZHs8ZIZERGRHnr13GGY5OXgcS0Vdrbw0XU5eo+BiIiISA/NPLQOjpmpSDKvw0CkBbxkRkRERLLHQERERESyx0tmREREFeQ6Y7euS6AKYg8RERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREcke7zIjIiLSQ3fNrdX+pYphICIiItJDrwau0HUJNQoDEWmkLM/cuPaJfxVUQkREVHEcQ0RERESyV60D0bx586BQKNRezZo1k+ZnZ2cjODgYderUgbm5OYYMGYKUlBS1dSQmJsLf3x+mpqaws7PDtGnTkJ+fX9W7QkRERNVYtb9k1rJlS+zfv196b2T0v5InT56M3bt3Y+vWrbCyskJISAhee+01HD9+HABQUFAAf39/ODg44MSJE0hKSkJAQABq1aqFRYsWVfm+kG7xMh8R1SSL9v4HVtkZSDO2wId9QnRdjt6r9oHIyMgIDg4OxaanpaVhzZo12LhxI1555RUAwLp169C8eXP8/vvv6NSpEyIjI3Hu3Dns378f9vb2aNOmDRYuXIgPPvgA8+bNg1KprOrdISIi0ooel/+EY2Yqkszr6LqUGqFaXzIDgIsXL8LJyQkNGzbEiBEjkJiYCACIiYlBXl4efH19pbbNmjVDgwYNEB0dDQCIjo5Gq1atYG9vL7Xx8/NDeno64uPjS91mTk4O0tPT1V5ERERUc1XrQNSxY0dERERg7969WLVqFa5evYquXbsiIyMDycnJUCqVqF27ttoy9vb2SE5OBgAkJyerhaGi+UXzShMWFgYrKyvp5ezsrN0dIyIiomqlWl8y69u3r/T/1q1bo2PHjnBxccGPP/4IExOTStvuzJkzERoaKr1PT09nKCIiIqrBqnUgelbt2rXRpEkTXLp0Cb169UJubi4ePnyo1kuUkpIijTlycHDAH3/8obaOorvQShqXVESlUkGlUml/B6ja48BrIiJ5qtaXzJ6VmZmJy5cvw9HREV5eXqhVqxYOHDggzU9ISEBiYiK8vb0BAN7e3vj7779x584dqU1UVBQsLS3RokWLKq+fiIiIqqdq3UM0depUDBgwAC4uLrh9+zbmzp0LQ0NDDBs2DFZWVggKCkJoaChsbGxgaWmJ9957D97e3ujUqRMAoHfv3mjRogXefvttLFmyBMnJyZg9ezaCg4PZA0RERESSah2Ibt68iWHDhiE1NRV169ZFly5d8Pvvv6Nu3boAgOXLl8PAwABDhgxBTk4O/Pz88NVXX0nLGxoaYteuXfjXv/4Fb29vmJmZITAwEAsWLNDVLpWoLJdpiIiIqPJU60C0efPm5843NjbGypUrsXLlylLbuLi4YM+ePdoujYiIiGqQah2IiIiIqGQ7W3SHVXYm0ozNdV1KjcBAREREpIfCeryj6xJqFL26y4yIiIioMjAQERERkewxEBEREZHscQwRERGRHjrw7XjYZabijnkd9Bwbruty9B57iIiIiPSQae5jWOQ+hmnuY12XUiMwEBEREZHs8ZIZVRp+UCoREekL9hARERGR7LGHiKic2PNFRFTzsIeIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+DqomIiPTQLL9gGOfnIttIqetSagQGIiIiIj10sFEHXZdQozAQERERkcZqyqNIOIaIiIiIZI89RERERHrII/kSlAV5yDWshbMOjXRdjt5jIKIaoSxdtkRENcm3Py2EY2YqkszrwDt4va7L0Xu8ZEZERESyx0BEREREssdLZkSVoKbcdUFEJBfsISIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2eNdZkRERM/BB7/KAwMRERGRHvIdswoKAELXhdQQDESkU3xeDxGRZrJUprouoUbhGCIiIiKSPfYQERGR3mHvMmkbAxEREZEeCvrjZ1jkPkKG0hRrOgzWdTl6j4GIiIhID435cwccM1ORZF6HgUgLGIio2uMtr0REVNk4qJqIiIhkjz1ERERUrbBXmHSBPUREREQkewxEREREJHu8ZEZERDUSn1VE5cEeIiIiIpI9BiIiIiKSPV4yI9IRducTUUWcdXBH0iNbpJpa6bqUGoGBiIiIZEufb/EfO2SOrkuoUXjJjIiIiGSPgYiIiIhkj4GIiIiIZI9jiIiIiPTQtz8tQJ1HaUg1teJ4Ii1gICIiItJDHsmX4ZiZiiTzOroupUZgICIioiqjz3d1Uc3GQERUjfFZRUREVYOBiEjP1dTQpK2eBH3cd6KaRh9+TskqEK1cuRKffvopkpOT4enpiS+//BIdOnTQdVlEslPdLpvoww9rIqpcsglEW7ZsQWhoKMLDw9GxY0esWLECfn5+SEhIgJ2dna7LI6pUcv6Fr63wJedjWFbVLegSlYdsAtGyZcswduxYjB49GgAQHh6O3bt3Y+3atZgxY4aOqyPSPW39wpfzL8Wq3PeqDl9y/rqSPMgiEOXm5iImJgYzZ86UphkYGMDX1xfR0dE6rIxIv/CXYvXBrwWRdskiEN27dw8FBQWwt7dXm25vb48LFy4Ua5+Tk4OcnBzpfVpaGgAgPT29UuorzHlUKeslIqKaK0MUwuz//60Jv0cq43ds0TqFEC9sK4tAVF5hYWGYP39+senOzs46qIaIiKi4pkX/yXoArHhTl6VohdWKylt3RkYGrKysnttGFoHI1tYWhoaGSElJUZuekpICBweHYu1nzpyJ0NBQ6X1hYSHu37+POnXqQKFQVHq9mkpPT4ezszNu3LgBS0tLXZdTY/C4Vh4e28rDY1t5eGwrR2UcVyEEMjIy4OTk9MK2sghESqUSXl5eOHDgAAYNGgTgScg5cOAAQkJCirVXqVRQqVRq02rXrl0FlWqHpaUlv0krAY9r5eGxrTw8tpWHx7ZyaPu4vqhnqIgsAhEAhIaGIjAwEO3atUOHDh2wYsUKZGVlSXedERERkXzJJhC99dZbuHv3LubMmYPk5GS0adMGe/fuLTbQmoiIiORHNoEIAEJCQkq8RFZTqFQqzJ07t9jlPqoYHtfKw2NbeXhsKw+PbeXQ9XFViLLci0ZERERUgxnougAiIiIiXWMgIiIiItljICIiIiLZYyAiIiIi2WMg0jMrV66Eq6srjI2N0bFjR/zxxx9lWm7z5s1QKBTSgylJXXmP68OHDxEcHAxHR0eoVCo0adIEe/bsqaJq9Ut5j+2KFSvQtGlTmJiYwNnZGZMnT0Z2dnYVVasfjh49igEDBsDJyQkKhQI7dux44TKHDx/GSy+9BJVKhUaNGiEiIqLS69RH5T2227dvR69evVC3bl1YWlrC29sb+/btq5pi9Ywm522R48ePw8jICG3atKm0+hiI9MiWLVsQGhqKuXPn4q+//oKnpyf8/Pxw586d5y537do1TJ06FV27dq2iSvVLeY9rbm4uevXqhWvXrmHbtm1ISEjAt99+i3r16lVx5dVfeY/txo0bMWPGDMydOxfnz5/HmjVrsGXLFnz44YdVXHn1lpWVBU9PT6xcubJM7a9evQp/f3/06NEDcXFxmDRpEsaMGcNf3CUo77E9evQoevXqhT179iAmJgY9evTAgAEDEBsbW8mV6p/yHtsiDx8+REBAAHr27FlJlf0/QXqjQ4cOIjg4WHpfUFAgnJycRFhYWKnL5Ofni5dfflmsXr1aBAYGioEDB1ZBpfqlvMd11apVomHDhiI3N7eqStRb5T22wcHB4pVXXlGbFhoaKjp37lypdeozAOLnn39+bpvp06eLli1bqk176623hJ+fXyVWpv/KcmxL0qJFCzF//nztF1SDlOfYvvXWW2L27Nli7ty5wtPTs9JqYg+RnsjNzUVMTAx8fX2laQYGBvD19UV0dHSpyy1YsAB2dnYICgqqijL1jibHdefOnfD29kZwcDDs7e3h4eGBRYsWoaCgoKrK1guaHNuXX34ZMTEx0mW1K1euYM+ePejXr1+V1FxTRUdHq30dAMDPz++5PztIM4WFhcjIyICNjY2uS6kR1q1bhytXrmDu3LmVvi1ZPalan927dw8FBQXFPmrE3t4eFy5cKHGZY8eOYc2aNYiLi6uCCvWTJsf1ypUrOHjwIEaMGIE9e/bg0qVLmDBhAvLy8qrkm1ZfaHJshw8fjnv37qFLly4QQiA/Px/jx4/nJbMKSk5OLvHrkJ6ejsePH8PExERHldU8n332GTIzM/Hmm2/quhS9d/HiRcyYMQO//fYbjIwqP66wh6iGysjIwNtvv41vv/0Wtra2ui6nRiksLISdnR2++eYbeHl54a233sKsWbMQHh6u69L03uHDh7Fo0SJ89dVX+Ouvv7B9+3bs3r0bCxcu1HVpRC+0ceNGzJ8/Hz/++CPs7Ox0XY5eKygowPDhwzF//nw0adKkSrbJHiI9YWtrC0NDQ6SkpKhNT0lJgYODQ7H2ly9fxrVr1zBgwABpWmFhIQDAyMgICQkJcHd3r9yi9UB5jysAODo6olatWjA0NJSmNW/eHMnJycjNzYVSqazUmvWFJsf2o48+wttvv40xY8YAAFq1aoWsrCyMGzcOs2bNgoEB/4bThIODQ4lfB0tLS/YOacnmzZsxZswYbN26tdjlSSq/jIwMnDp1CrGxsdJnkBYWFkIIASMjI0RGRuKVV17R6jb500VPKJVKeHl54cCBA9K0wsJCHDhwAN7e3sXaN2vWDH///Tfi4uKk16uvvirdZeLs7FyV5Vdb5T2uANC5c2dcunRJCpgA8M8//8DR0ZFh6CmaHNtHjx4VCz1FwVPwYxc15u3trfZ1AICoqKhSvw5UPps2bcLo0aOxadMm+Pv767qcGsHS0rLY77Dx48ejadOmiIuLQ8eOHbW/0Uobrk1at3nzZqFSqURERIQ4d+6cGDdunKhdu7ZITk4WQgjx9ttvixkzZpS6PO8yK1l5j2tiYqKwsLAQISEhIiEhQezatUvY2dmJjz/+WFe7UG2V99jOnTtXWFhYiE2bNokrV66IyMhI4e7uLt58801d7UK1lJGRIWJjY0VsbKwAIJYtWyZiY2PF9evXhRBCzJgxQ7z99ttS+ytXrghTU1Mxbdo0cf78ebFy5UphaGgo9u7dq6tdqLbKe2x/+OEHYWRkJFauXCmSkpKk18OHD3W1C9VWeY/tsyr7LjMGIj3z5ZdfigYNGgilUik6dOggfv/9d2le9+7dRWBgYKnLMhCVrrzH9cSJE6Jjx45CpVKJhg0bin//+98iPz+/iqvWD+U5tnl5eWLevHnC3d1dGBsbC2dnZzFhwgTx4MGDqi+8Gjt06JAAUOxVdCwDAwNF9+7diy3Tpk0boVQqRcOGDcW6deuqvG59UN5j27179+e2p//R5Lx9WmUHIoUQ7IcmIiIieeMYIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIionK6du0aFAoF4uLidF0KEWkJAxGRjIwaNQoKhQIKhQK1atWCm5sbpk+fjuzsbF2XVmaHDx+GQqHAw4cPq2R7o0aNwqBBg9SmOTs7IykpCR4eHpW67Xnz5klfr6dfzZo1q9TtEskRP+2eSGb69OmDdevWIS8vDzExMQgMDIRCocDixYt1XZpW5ebmVtqH7RoaGsLBwaFS1v2sli1bYv/+/WrTjIxK/9Fd0n4XFBRAoVAU++DcF9F0OSJ9xLOcSGZUKhUcHBzg7OyMQYMGwdfXF1FRUdL8wsJChIWFwc3NDSYmJvD09MS2bdvU1hEfH4/+/fvD0tISFhYW6Nq1Ky5fviwtv2DBAtSvXx8qlQpt2rTB3r17pWWLLjdt374dPXr0gKmpKTw9PREdHS21uX79OgYMGABra2uYmZmhZcuW2LNnD65du4YePXoAAKytraFQKDBq1CgAgI+PD0JCQjBp0iTY2trCz8+vxEtbDx8+hEKhwOHDh1+4P/PmzcP69evxyy+/SL0zhw8fLnG9R44cQYcOHaBSqeDo6IgZM2YgPz9fmu/j44OJEydi+vTpsLGxgYODA+bNm/fCr5eRkREcHBzUXra2ttJ8V1dXLFy4EAEBAbC0tMS4ceMQERGB2rVrY+fOnWjRogVUKhUSExPx4MEDBAQEwNraGqampujbty8uXrworau05YjkgIGISMbOnj2LEydOqPUohIWF4bvvvkN4eDji4+MxefJkjBw5EkeOHAEA3Lp1C926dYNKpcLBgwcRExODd955R/rl//nnn2Pp0qX47LPPcObMGfj5+eHVV19V+8ULALNmzcLUqVMRFxeHJk2aYNiwYdI6goODkZOTg6NHj+Lvv//G4sWLYW5uDmdnZ/z0008AgISEBCQlJeHzzz+X1rl+/XoolUocP34c4eHhZToGz9ufqVOn4s0330SfPn2QlJSEpKQkvPzyyyWuo1+/fmjfvj1Onz6NVatWYc2aNfj444/V2q1fvx5mZmY4efIklixZggULFqiFUU199tln8PT0RGxsLD766CMAwKNHj7B48WKsXr0a8fHxsLOzw6hRo3Dq1Cns3LkT0dHREEKgX79+yMvLk9ZV0nJEslBpHxtLRNVOYGCgMDQ0FGZmZkKlUgkAwsDAQGzbtk0IIUR2drYwNTUVJ06cUFsuKChIDBs2TAghxMyZM4Wbm5vIzc0tcRtOTk7i3//+t9q09u3biwkTJgghhLh69aoAIFavXi3Nj4+PFwDE+fPnhRBCtGrVSsybN6/E9Rd9YvaDBw/Upnfv3l20bdtWbVrRtmJjY6VpDx48EADEoUOHyrQ/gYGBYuDAgc9d74cffiiaNm0qCgsLpTYrV64U5ubmoqCgQKqvS5cuxY7LBx98UOJ2hXjy6d4GBgbCzMxM7fXuu+9KbVxcXMSgQYPUllu3bp0AIOLi4qRp//zzjwAgjh8/Lk27d++eMDExET/++GOpyxHJBccQEclMjx49sGrVKmRlZWH58uUwMjLCkCFDAACXLl3Co0eP0KtXL7VlcnNz0bZtWwBAXFwcunbtilq1ahVbd3p6Om7fvo3OnTurTe/cuTNOnz6tNq1169bS/x0dHQEAd+7cQbNmzTBx4kT861//QmRkJHx9fTFkyBC19qXx8vIqwxFQ97z9Kavz58/D29sbCoVCmta5c2dkZmbi5s2baNCgAQAU2wdHR0fcuXPnuetu2rQpdu7cqTbN0tJS7X27du2KLadUKtW2d/78eRgZGaFjx47StDp16qBp06Y4f/58qcsRyQUDEZHMmJmZoVGjRgCAtWvXwtPTE2vWrEFQUBAyMzMBALt370a9evXUllOpVAAAExMTrdTxdAApChKFhYUAgDFjxsDPzw+7d+9GZGQkwsLCsHTpUrz33nsv3LenFQ0GFkJI056+PARob3/K4tnQpVAopH0ujVKplL5epXl2v4En+/V0QCsrTZcj0nccQ0QkYwYGBvjwww8xe/ZsPH78WG0gbaNGjdRezs7OAJ70cvz222/FggXwpOfCyckJx48fV5t+/PhxtGjRoly1OTs7Y/z48di+fTumTJmCb7/9FgCk8U4FBQUvXEfdunUBAElJSdK0Z58d9Lz9Kdrei7bVvHlzaUxOkePHj8PCwgL169d/YZ1VoXnz5sjPz8fJkyelaampqUhISCj314aoJmIgIpK5N954A4aGhli5ciUsLCwwdepUTJ48GevXr8fly5fx119/4csvv8T69esBACEhIUhPT8fQoUNx6tQpXLx4Ed9//z0SEhIAANOmTcPixYuxZcsWJCQkYMaMGYiLi8P7779f5pomTZqEffv24erVq/jrr79w6NAhNG/eHADg4uIChUKBXbt24e7du1KvVklMTEzQqVMnfPLJJzh//jyOHDmC2bNnq7V50f64urrizJkzSEhIwL1790oMThMmTMCNGzfw3nvv4cKFC/jll18wd+5chIaGVviW9fz8fCQnJ6u9UlJSyr2exo0bY+DAgRg7diyOHTuG06dPY+TIkahXrx4GDhxYoRqJagIGIiKZMzIyQkhICJYsWYKsrCwsXLgQH330EcLCwtC8eXP06dMHu3fvhpubG4An404OHjyIzMxMdO/eHV5eXvj222+ly0ETJ05EaGgopkyZglatWmHv3r3YuXMnGjduXOaaCgoKEBwcLG2/SZMm+OqrrwAA9erVw/z58zFjxgzY29sjJCTkuetau3Yt8vPz4eXlhUmTJhW78+tF+zN27Fg0bdoU7dq1Q926dYv1fhXVtGfPHvzxxx/w9PTE+PHjERQUVCx8aSI+Ph6Ojo5qLxcXF43WtW7dOnh5eaF///7w9vaGEAJ79uyp0PgpoppCIZ7u4yUiIiKSIfYQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7P0fayprkeh6HJcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a threshold for anomaly detection\n",
    "threshold = np.percentile(reconstruction_errors, 70)\n",
    "\n",
    "plt.hist(reconstruction_errors, bins=50)\n",
    "plt.axvline(threshold, color='r', linestyle='dashed', linewidth=2)\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Reconstruction Error Distribution (Training Data)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1511/1511\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step\n"
     ]
    }
   ],
   "source": [
    "reconstructions_test = autoencoder.predict(S_X_test)\n",
    "reconstruction_errors_test = np.mean(np.square(S_X_test - reconstructions_test), axis=1)\n",
    "anomalies = reconstruction_errors_test > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalies detected: 7252\n",
      "True Positives: 0\n",
      "False Positives: 7252\n",
      "False Negatives: 24174\n",
      "\n",
      "Accuracy: 0.35000413667576735\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "def compare_results(anomalies_found, anomaly_label):\n",
    "    anomaly_labels = anomaly_label == -1\n",
    "\n",
    "    # Compare the arrays\n",
    "    correctly_identified = (anomalies_found == anomaly_labels)\n",
    "\n",
    "    # Calculate the number of correctly identified anomalies\n",
    "    correct_count = correctly_identified.sum()\n",
    "\n",
    "    # Calculate the total number of anomalies and normal instances\n",
    "    total_anomalies = anomaly_labels.sum()\n",
    "    total_normal = (~anomaly_labels).sum()\n",
    "\n",
    "    num_anomalies_detected = anomalies_found.sum()\n",
    "    print(f\"Number of anomalies detected: {num_anomalies_detected}\")\n",
    "\n",
    "    # Calculate accuracy, precision, recall, etc.\n",
    "    accuracy = correct_count / len(anomalies_found)\n",
    "\n",
    "    true_positives = (anomalies_found & anomaly_labels).sum()\n",
    "    false_positives = (anomalies_found & ~anomaly_labels).sum()\n",
    "    false_negatives = (~anomalies_found & anomaly_labels).sum()\n",
    "\n",
    "    print(f\"True Positives: {true_positives}\")\n",
    "    print(f\"False Positives: {false_positives}\")\n",
    "    print(f\"False Negatives: {false_negatives}\")\n",
    "\n",
    "    if anomalies_found.sum() > 0:\n",
    "        precision = true_positives / anomalies_found.sum()\n",
    "    else:\n",
    "        precision = 0.0  # To handle division by zero\n",
    "\n",
    "    if total_anomalies > 0:\n",
    "        recall = true_positives / total_anomalies\n",
    "    else:\n",
    "        recall = 0.0  # To handle division by zero\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "\n",
    "compare_results(anomalies, S_y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
